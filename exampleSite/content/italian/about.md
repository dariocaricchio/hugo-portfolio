---
title : "SU DI ME"
image : "https://res.cloudinary.com/dario-caricchio/image/upload/v1621548143/backgrounds/portrait_dlnmps.jpg" # "images/backgrounds/portrait.jpg"
# button
button:
  enable : true
  label : "SCARICA IL MIO CV"
  link : "https://drive.google.com/file/d/192RNnc2djowBEj-nhUmH2QABdKpMJIQd/view?usp=sharing"

########################### Experience ##############################
experience:
  enable : true
  title : "ESPERIENZE PRINCIPALI"
  experience_list:

    # experience item loop
    - name : "Big Data Engineer Consultant"
      company : "British Multinational Telecommunications Company (Italian division) on behalf of Capgemini"
      duration : "06/06/2022 â€“ in corso"
      content : 'â–º Varie attivitÃ  di *Application Management Services* su **GCP** con diversi servizi come **Composer** e relativi DAG di **Airflow** in **Python**, **Cloud Storage**, **Cloud Functions**, analisi in **BigQuery** con **SQL**, **Dataproc**, **Firestore**.'

    - name : "Big Data Engineer - Consulente"
      company : "Azienda Britannica Multinazionale di Telecomunicazioni (divisione italiana) per conto di Capgemini"
      duration : "06/06/2022 â€“ 15/03/2024"
      content : "â–º Analisi e sviluppo di job **Spark** in **Scala** i quali vengono eseguiti su cluster **Dataproc** su **GCP** al fine di processare dati presenti in **Google Cloud Storage** per mascherare informazioni sensibili.<br>
      â–º Orchestrazione, sviluppo, mantenimento e verifica DAG di **Airflow** in **Python** con **PySpark** attraverso i servizi **GCP** quali **Composer**, **Dataproc** e **Cloud Storage** per l'analisi dei dati.<br>
      â–º Operazioni di tuning, bug-fixing, analisi delle performance e miglioramento di job **Spark** preesistenti.<br>
      â–º Progettazione, analisi e sviluppo di funzioni, stored procedures e tabelle in **BigQuery** usando **SQL** e vari connettori, come **Airflow**, **Cloud Storage** e **PySpark**.<br>
      â–º Progettazione, sviluppo e potenziamento di soluzioni **architetturali** attraverso lâ€™uso di **GCP Cloud Functions**, **BigQuery** e **Composer**.<br>
      â–º Progettazione, sviluppo e potenziamento di **DevOps** attraverso lâ€™uso di **GCP Cloud Build** e **Cloud Artifact**, con gestione dei repository, template e relative impostazioni."
    
    - name : "Big Data Engineer - Consulente"
      company : "Azienda Britannica Multinazionale di Telecomunicazioni (divisione italiana) per conto di Azienda Giapponese Multinazionale di Servizi IT e Consulenza (divisione italiana)"
      duration : "25/10/2021 â€“ 31/05/2022"
      content : "â–º Analisi e sviluppo di job **Spark** in **Scala** i quali vengono eseguiti su cluster **Dataproc** su **GCP** al fine di processare dati presenti in **Google Cloud Storage** per mascherare informazioni sensibili.<br>
      â–º Orchestrazione, sviluppo, mantenimento e verifica DAG di **Airflow** in **Python** con **PySpark** attraverso i servizi **GCP** quali **Composer**, **Dataproc** e **Cloud Storage** per l'analisi dei dati.<br>
      â–º Operazioni di tuning, bug-fixing, analisi delle performance e miglioramento di job **Spark** preesistenti.<br>
      â–º Progettazione, analisi e sviluppo di funzioni, stored procedures e tabelle in **BigQuery** usando **SQL** e vari connettori, come **Airflow**, **Cloud Storage** e **PySpark**."

    # experience item loop
    - name : "ML Engineer - Consulente"
      company : "Azienda Americana-Britannica-Svizzera Multinazionale di Distribuzione Farmaceutica per conto di Azienda Italiana di Digital Solution"
      duration : "30/03/2021 â€“ 22/10/2021"
      content : "â–º Analisi e sviluppo di un processo automatico per l'individuazione di inconsistenze dello schema e per rilevare l'esistenza di chiavi primarie duplicate utilizzando il linguaggio **Python** e **PySpark** e in generale le tecnologie **Azure** attraverso sia **Databricks Workspace** sia sviluppando in ambiente locale attraverso **databricks-connect** e **databricks-cli**.<br>
      â–º Generazione di **Delta Table** curate a partire da un **ADLS storage account** curato; le tabelle finali sono equivalenti alle corrispettive tabelle curate presenti su **Synapse** (**ADW**).<br>
      â–º Valutazione di algoritmi di Intelligenza Artificiale giÃ  in essere."


    # experience item loop
    - name : "Big Data Engineer - Consulente"
      company : "Azienda Britannica Multinazionale di Media e Telecomunicazioni (divisione tedesca e austriaca) per conto di Azienda Giapponese Multinazionale di Servizi IT e Consulenza (divisione italiana)"
      duration : "1/11/2020 - 15/03/2021"
      content : "â–º Ingegnere Big Data su progetto cliente utilizzando **Scala** e **Java** come linguaggi di programmazione e **Google Cloud Platform**.<br>
      â–º Design e sviluppo di processi **Spark** in **Scala** usando i servizi **GCP** come **Google Cloud Storage**, **Pub/Sub**, **Google DLP** ed altri.<br>
      â–º Design e sviluppo di processi **Apache Beam** per **Dataflow** usando **SCIO**, *una libreria di Beam in Scala*, **Kafka** e tecnologie **GCS** per l'elaborazione dei dati all'interno dell'**ingestion** layer in contesti sia **batch** che **streaming**.<br>
      â–º Design e sviluppo di un POC per evidenziare varie strategie legate alla **sicurezza** dei precessi **Dataflow** attraverso **Google KMS**, **DLP** e la libreria crittografica **Google Tink**."

    # experience item loop
    - name : "Big Data Engineer - Consulente"
      company : "Azienda Italiana Multinazionale di ElettricitÃ -Gas per conto di Azieda Francese Multinazionale di Servizi IT e Consulenza"
      duration : "23/09/2019 â€“ 15/10/2020"
      content : 'â–º Ingegnere Big Data su progetto Enel Next utilizzando **Scala** e **Java** come linguaggi di programmazione e ambiente **Hadoop Cloudera**.<br>
      â–º Design e sviluppo di processi **Spark** attraverso una piattaforma **Scala** proprietaria costruita al di sopra dello **Spark Core**.<br>
      â–º Design e sviluppo di strumenti per la **Data Quality** usando le standard **Spark Core API** (**Spark** 2.4.5 e **Scala** 2.11.12).<br>
      â–º Design e sviluppo di strumenti per il **Reporting** basandosi su strumenti quali **HIVE**, **Impala**, file **Parquet**/**ORC**/**Avro** su **S3** e **HDFS** al fine di ottenere la **materializzazione dei dataset**, **Data Visualization** e **CSV/Excel file export**.'

    # experience item loop
    - name : "Intern"
      company : "Hamlyn Centre - Imperial College of London"
      duration : "15/02/2019 â€“ 18/07/2019"
      content : 'â–º Borsa di studio per il programma "Erasmus+ Traineeship BET for jobs".<br>
      â–º Sviluppo di un **algoritmo di compressione** discusso in letteratura per sensori ECG con linguaggio di programmazione **C**.<br>
      â–º Lavoro su "**abnormal gait detection**" (rilevamento della camminata anomala) usando il linguaggio di programmazione **Python** e relative librerie, combinando algoritmi di **machine learning** con metodologie per il **pre-processing**, **feature extraction**, **dataset creation**, **data visualization**, **discrete wavelet transformation** e **classificazione**.'

############################### Skill #################################
skill:
  enable : true
  title : "COMPETENZE"
  skill_list:
    # skill item loop
    - name : "Computer Engineering"
      percentage : "98%"

    # skill item loop
    - name : "Big Data"
      percentage : "85%"

    # skill item loop
    - name : "Software Development"
      percentage : "90%"

    # skill item loop
    - name : "Machine Learning"
      percentage : "70%"

    # skill item loop
    - name : "Servizi Cloud"
      percentage : "80%"

  subtitle: CERTIFICAZIONI
  description: "Puoi dare un'occhiata alle mie certificazioni sul mio [Profilo Linkedin](https://www.linkedin.com/in/dariocaricchio/details/certifications/)."
  gcp_image: "https://templates.images.credential.net/16590189412502689960209276019161.png"
  gcp_link: "https://www.credential.net/fa2d0a2c-ea37-4107-9f7e-d63d42b78591"


# custom style
custom_class: ""
custom_attributes: ""
custom_css: ""
---

Sono Dario, un Ingegnere Informatico. Adoro risolvere problemi attraverso la programmazione e lo sviluppo di codice, Ãˆ la mia passione. Sono sempre disponibile per progettare e sviluppare soluzioni software di varia natura. Posso anche aiutare a descrivere te stesso nel miglior modo possibile con un sito web.<br>Non importa quanto possa essere difficile un problema, farÃ² tutto il possibile per trovare una soluzione e completare il lavoro. Rimaniamo in contatto! ðŸ˜Š
