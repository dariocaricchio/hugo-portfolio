---
title : "KNOW MORE <br> ABOUT ME"
image : "https://res.cloudinary.com/dario-caricchio/image/upload/v1621548143/backgrounds/portrait_dlnmps.jpg" # "images/backgrounds/portrait.jpg"
# button
button:
  enable : true
  label : "DOWNLOAD MY CV"
  link : "https://drive.google.com/file/d/1d4y3cCBuzzabenr7GooZMVZOmY_bXY7X/view?usp=sharing"

########################### Experience ##############################
experience:
  enable : true
  title : "MAIN EXPERIENCES"
  experience_list:

    # experience item loop
    - name : "Big Data Engineer Consultant"
      company : "Vodafone Italia on behalf of Capgemini"
      duration : "06/06/2022 â€“ Ongoing"
      content : 'â–º Design and develop of Spark jobs on Scala which run on GCP Dataproc clusters to process data on Google Storage for masking purposes.<br>
      â–º Airflow DAGs orchestration, develop, mantainance and testing on Python with PySpark using GCP Composer, Dataproc and Google Storage for analytics reasons.<br>
      â–º Existing Spark jobs tuning, bug fixing, performance analysis and improvements.<br>
      â–º Design, develop and maintenance of BigQuery functions, stored procedures and tables using SQL and connecting with Airflow, Google Storage and Pyspark.'

    - name : "Big Data Engineer Consultant"
      company : "British Multinational Telecommunications Company (Italian division) on behalf of a Japanese Multinational IT Service and Consulting Company (Italian division)"
      duration : "25/10/2021 â€“ 31/05/2022"
      content : 'â–º Design and develop of Spark jobs on Scala which run on GCP Dataproc clusters to process data on Google Storage for masking purposes.<br>
      â–º Airflow DAGs orchestration, develop, mantainance and testing on Python with PySpark using GCP Composer, Dataproc and Google Storage for analytics reasons.<br>
      â–º Existing Spark jobs tuning, bug fixing, performance analysis and improvements.<br>
      â–º Design, develop and maintenance of BigQuery functions, stored procedures and tables using SQL and connecting with Airflow, Google Storage and Pyspark.'

    # experience item loop
    - name : "ML Engineer Consultant"
      company : "American-British-Swiss Multinational Retail Pharmacy Company on behalf of an Italian Digital Solution Company"
      duration : "30/03/2021 â€“ 22/10/2021"
      content : 'â–º Analysis and development of an automatic process to detect Schema Inconsistencies and detect the existing of Duplicated Primary Keys using Python, PySpark and more in general Azure tecnologies; both Databricks Workspace and local environment using databrick-connect and databricks-cli have been used.<br>
      â–º Generation of curated delta tables starting from the curated ADLS storage account; the curated delta tables are equivalent to the curated tables found on Synapse (ADW).<br>
      â–º Enhancement of existing AI Algorithms.'

    # experience item loop
    - name : "Big Data Engineer Consultant"
      company : "British Multinational Media and Telecommunication Company (German and Austrian division) on behalf of a Japanese Multinational IT Service and Consulting Company (Italian division)"
      duration : "1/11/2020 - 15/03/2021"
      content : 'â–º Big Data Engineer on client project using Scala and Java programming languages and Google Cloud Platform.<br>
      â–º Design and develop of Spark jobs on Scala using GCP services like Google Cloud Storage, Pub/Sub, Google DLP and many more.<br>
      â–º Design and develop of Apache Beam jobs for Dataflow using SCIO, a Beam Scala framework, for both batch and streaming contexts using GCS and Kafka technologies into the ingestion layer.<br>
      â–º Design and develop of a POC for security strategies for Dataflow jobs using Google KMS, DLP and Google Tink crypto library.'

    # experience item loop
    - name : "Big Data Engineer Consultant"
      company : "Italian Multinational Electricity-Gas Company on behalf of a French Multinational IT Service and Consulting Company"
      duration : "23/09/2019 â€“ 15/10/2020"
      content : 'â–º Big Data Engineer on Enel Next Project using Scala and Java programming languages, Hadoop Cloudera Distribution.<br>
      â–º Design and develop of Spark jobs on proprietary Scala platform built on top of Spark core.<br>
      â–º Design and develop of Data Quality Tool using standard Spark Core API (spark 2.4.5 and Scala 2.11.12).<br>
      â–º Design and Develop of Reporting tools based on HIVE, Impala, Parquet/ORC/Avro files on S3 and HDFS for dataset materialization, Data Visualization and CSV/Excel file export.'

    # experience item loop
    - name : "Intern"
      company : "Hamlyn Centre - Imperial College of London"
      duration : "15/02/2019 â€“ 18/07/2019"
      content : 'Scholarship for "Erasmus+ Traineeship BET for jobs". I developed a compression algorithm discussed in literature for an ECG sensor using C language. Furthermore, I worked on "abnormal gait detection" using Python language libraries combined with machine learning algorithms and methods for pre-processing, feature extraction, dataset creation, data visualization, discrete wavelet transformation and classification.'

############################### Skill #################################
skill:
  enable : true
  title : "SKILL"
  skill_list:
    # skill item loop
    - name : "Computer Engineering"
      percentage : "98%"

    # skill item loop
    - name : "Big Data"
      percentage : "85%"

    # skill item loop
    - name : "Software Development"
      percentage : "90%"

    # skill item loop
    - name : "Machine Learning"
      percentage : "70%"

    # skill item loop
    - name : "Cloud Services"
      percentage : "80%"
  
  subtitle: CERTIFICATIONS
  description: "See my certifications on my [Linkedin profile](https://www.linkedin.com/in/dariocaricchio/details/certifications/)."


# custom style
custom_class: ""
custom_attributes: ""
custom_css: ""
---

It's Dario, a Software Engineer. I love to solve problems with coding, it's my passion. I am here to help you to design and develop software solutions. I can also help you to describe yourself in the best way with a web site.<br>No matter how difficult your problem is, I will do whatever I can to find a way and complete your work anyway. Stay connected with me! ðŸ˜Š