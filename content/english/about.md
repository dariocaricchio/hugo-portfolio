---
title : "KNOW MORE <br> ABOUT ME"
image : "https://res.cloudinary.com/dario-caricchio/image/upload/v1621548143/backgrounds/portrait_dlnmps.jpg" # "images/backgrounds/portrait.jpg"
# button
button:
  enable : true
  label : "DOWNLOAD MY CV"
  link : "https://drive.google.com/file/d/16X7reW48e_fAFlfH1efaTgpcd7vsH3-F/view?usp=sharing"

########################### Experience ##############################
experience:
  enable : true
  title : "MAIN EXPERIENCES"
  experience_list:

    # experience item loop
    - name : "Big Data Engineer Consultant"
      company : "American Multinational Manufacturer and Marketer Company (both USA and EMEA division) on behalf of Capgemini"
      duration : "06/06/2022 â€“ Ongoing"
      content : 'â–º *Application Management Services* activities on **GCP** using various cloud services like **Composer** and the related **Airflow** DAG written in **Python**, **Cloud Storage**, **Cloud Functions**, analysis on **BigQuery** using **SQL**, **Dataproc**, **Firestore**.'

    - name : "Big Data Engineer Consultant"
      company : "British Multinational Telecommunications Company (Italian division) on behalf of Capgemini"
      duration : "06/06/2022 â€“ 15/03/2024"
      content : 'â–º Design and development of **Spark** jobs on **Scala** which run on **GCP** **Dataproc** clusters to process data on Google **Cloud Storage** for masking purposes.<br>
      â–º **Airflow** DAGs orchestration, development, mantainance and testing on **Python** with **PySpark** using **GCP** **Composer**, **Dataproc** and **Cloud Storage** for analytics reasons.<br>
      â–º Existing **Spark** jobs tuning, bug fixing, performance analysis and improvements.<br>
      â–º Design, development and maintenance of BigQuery functions, stored procedures and tables using **SQL** and connecting with **Airflow**, **Cloud Storage** and **PySpark**.<br>
      â–º Design, develop and enhance **architectural solutions** using **GCP Cloud Functions**, **BigQuery** and **Composer**.<br>
      â–º Design, develop and enhance **DevOps solutions** using **GCP Cloud Build** and **Cloud Artifact**, with focus on repository and template management together with all the related settings.'

    - name : "Big Data Engineer Consultant"
      company : "British Multinational Telecommunications Company (Italian division) on behalf of a Japanese Multinational IT Service and Consulting Company (Italian division)"
      duration : "25/10/2021 â€“ 31/05/2022"
      content : 'â–º Design and development of **Spark** jobs on **Scala** which run on **GCP** **Dataproc** clusters to process data on Google **Cloud Storage** for masking purposes.<br>
      â–º **Airflow** DAGs orchestration, development, mantainance and testing on **Python** with **PySpark** using **GCP** **Composer**, **Dataproc** and **Cloud Storage** for analytics reasons.<br>
      â–º Existing **Spark** jobs tuning, bug fixing, performance analysis and improvements.<br>
      â–º Design, development and maintenance of BigQuery functions, stored procedures and tables using **SQL** and connecting with **Airflow**, **Cloud Storage** and **PySpark**.'

    # experience item loop
    - name : "ML Engineer Consultant"
      company : "American-British-Swiss Multinational Retail Pharmacy Company on behalf of an Italian Digital Solution Company"
      duration : "30/03/2021 â€“ 22/10/2021"
      content : 'â–º Analysis and development of an automatic process to detect Schema Inconsistencies and detect the existing of Duplicated Primary Keys using **Python**, **PySpark** and more in general **Azure** tecnologies; both **Databricks Workspace** and local environment using **databrick-connect** and **databricks-cli** have been used.<br>
      â–º Generation of curated **Delta Tables** starting from the curated **ADLS storage account**; the curated delta tables are equivalent to the curated tables found on **Synapse** (**ADW**).<br>
      â–º Enhancement of existing AI Algorithms.'

    # experience item loop
    - name : "Big Data Engineer Consultant"
      company : "British Multinational Media and Telecommunication Company (German and Austrian division) on behalf of a Japanese Multinational IT Service and Consulting Company (Italian division)"
      duration : "1/11/2020 - 15/03/2021"
      content : 'â–º Big Data Engineer on client project using **Scala** and **Java** programming languages and **Google Cloud Platform**.<br>
      â–º Design and development of **Spark** jobs on **Scala** using **GCP** services like Google **Cloud Storage**, **Pub/Sub**, **Google DLP** and many more.<br>
      â–º Design and development of **Apache Beam** jobs for **Dataflow** using SCIO, a *Beam Scala framework*, for both **batch** and **streaming** contexts using ***GCS*** and **Kafka** technologies into the **ingestion** layer.<br>
      â–º Design and development of a POC for **security** strategies for **Dataflow** jobs using **Google KMS**, **DLP** and **Google Tink** crypto library.'

    # experience item loop
    - name : "Big Data Engineer Consultant"
      company : "Italian Multinational Electricity-Gas Company on behalf of a French Multinational IT Service and Consulting Company"
      duration : "23/09/2019 â€“ 15/10/2020"
      content : 'â–º Big Data Engineer on Enel Next Project using **Scala** and **Java** programming languages, **Hadoop Cloudera Distribution**.<br>
      â–º Design and development of **Spark** jobs on proprietary **Scala** platform built on top of **Spark core**.<br>
      â–º Design and development of Data Quality Tool using standard **Spark Core API** (**Spark** 2.4.5 and **Scala** 2.11.12).<br>
      â–º Design and development of Reporting tools based on HIVE, Impala, Parquet/ORC/Avro files on S3 and HDFS for dataset materialization, Data Visualization and CSV/Excel file export.'

    # experience item loop
    - name : "Intern"
      company : "Hamlyn Centre - Imperial College of London"
      duration : "15/02/2019 â€“ 18/07/2019"
      content : 'Scholarship for "Erasmus+ Traineeship BET for jobs". <br>
      â–º Develop a **compression algorithm** discussed in literature for an ECG sensor using **C** programming language. <br>
      â–º "**Abnormal gait detection**" using **Python** programming language and libraries combined with **machine learning** algorithms and methods for **pre-processing**, **feature extraction**, **dataset creation**, **data visualization**, **discrete wavelet transform** and **classification**.'

############################### Skill #################################
skill:
  enable : true
  title : "SKILL"
  skill_list:
    # skill item loop
    - name : "Computer Engineering"
      percentage : "98%"

    # skill item loop
    - name : "Big Data"
      percentage : "85%"

    # skill item loop
    - name : "Software Development"
      percentage : "90%"

    # skill item loop
    - name : "Machine Learning"
      percentage : "70%"

    # skill item loop
    - name : "Cloud Services"
      percentage : "80%"
  
  subtitle: CERTIFICATIONS
  description: "See my certifications on my [Linkedin profile](https://www.linkedin.com/in/dariocaricchio/details/certifications/)."
  gcp_image: "https://templates.images.credential.net/16590189412502689960209276019161.png"
  gcp_link: "https://www.credential.net/fa2d0a2c-ea37-4107-9f7e-d63d42b78591"



# custom style
custom_class: ""
custom_attributes: ""
custom_css: ""
---

It's Dario, a Software Engineer. I love to solve problems with coding, it's my passion. I am here to help you to design and develop software solutions. I can also help you to describe yourself in the best way with a web site.<br>No matter how difficult your problem is, I will do whatever I can to find a way and complete your work anyway. Stay connected with me! ðŸ˜Š